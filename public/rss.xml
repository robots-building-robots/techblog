<?xml version="1.0"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>

<title>MODEL COLLAPSE</title>
<link></link>
<description>model collapse</description>
<atom:link href="/rss.xml" rel="self" type="application/rss+xml" />

<item>
     <title>Ditching Big Tech</title>
     <link>/posts/digital-sovereignty.html</link>
     <guid>/posts/digital-sovereignty.html</guid>
     <description><![CDATA[<p>In January 2026, I made the resolution to ditch US-based <em><strong>Big Tech</strong></em> as much as possible. We are living through a time of intensifying geopolitical tension and accelerating consolidation of digital infrastructure into the hands of a small number of empire-sized corporations who surveil our activity, mine our content, and sell it back to us like bottled water — or more like high fructose slop. </p>
<p>Most people don&#39;t care where their data lives, they choose what&#39;s cheap, familiar, and what works. The real costs of that convenience are never disclosed at the moment of choice. We have quietly normalized storing our digital lives under legal systems we never agreed to, in jurisdictions where we have no standing. That normalization is worth resisting.</p>
<p>For inspiration, I looked to Paris Marx&#39;s <a href="https://disconnect.blog/getting-off-us-tech-a-guide/" target="_blank" rel="noopener noreferrer">Getting Off US Tech</a>, Scott Galloway&#39;s <a href="https://www.resistandunsubscribe.com/" target="_blank" rel="noopener noreferrer">Resist and Unsubscribe</a>, and <a href="https://quitgpt.org/" target="_blank" rel="noopener noreferrer">QuitGPT</a>, but with a few different needs as a software developer focused open source tooling and the responsible use of AI, which, for better or worse, is now considered a professional baseline.</p>
<p><strong>Small Tech</strong>, not anti-technology, is the framing here. <strong>Digital Sovereignty</strong> isn&#39;t about national borders. It&#39;s about <strong>legibility</strong> — knowing who controls your data, under what law, with what accountability, and at what cost to community and the environment. For Canadians, there is a persistent gap between the privacy protections we assume we have and what is actually enforceable when a service runs on US infrastructure, regardless of where the physical servers actually sit.</p>
<p>Every time we signup or sign-in we should be asking ourselves: <em><strong>who unjustly profits from our convenience, and at whose expense?</strong></em></p>
<hr>
<h2 id="sovereignty-stack">Sovereignty Stack</h2>
<h3 id="infrastructure--identity">Infrastructure &amp; Identity</h3>
<p><em><strong>OS, Browser, Email, DNS:</strong></em> The base layer everything else flows through. Get this wrong and nothing above it matters. Hardest to change, highest stakes.</p>
<h3 id="professional-data">Professional Data</h3>
<p><em><strong>Code repositories, CI/CD, Cloud Documents, Web hosting, LLMs:</strong></em> Where the work lives: source code, client data, intellectual property, and the AI tools now inside the creative process. Stakes are professional and legal. Moderately difficult to migrate.</p>
<h3 id="communications--collaboration">Communications &amp; Collaboration</h3>
<p><em><strong>Messaging, Team Communications, Video calls, Calendar, Contacts:</strong></em> High-frequency and often sensitive, but the risk is metadata and surveillance rather than long-term data custody. Easier to change.</p>
<h3 id="convenience--consumption">Convenience &amp; Consumption</h3>
<p><em><strong>Maps, Media streaming, Social Media, Search:</strong></em> In some cases the highest friction to replace, but lowest sovereignty stakes.</p>
<hr>
<h2 id="migration-log">Migration Log</h2>
<p>I&#39;ve started where the cost and effort-to-impact ratio makes the most sense. Changing an email provider is manageable; replacing your OS without grinding your daily workload to a halt is a long-term goal for me. What follows is an ongoing log of where I started, where I&#39;m moving, and why. </p>
<hr>
<p>Work-in-progress</p>
<hr>
<blockquote>
<p>&quot;There is no situation that is morally more evil than the situation in which evil has been so fully integrated into the situation that the individual itself is spared from being evil […] The machines that populate our world have spared us from incurring guilt, just as they have relieved us from baking bread or from calculating statistics.&quot; — <em><strong>Güther Anders</strong></em>.</p>
</blockquote>
<hr>]]></description>
</item>
<item>
     <title>About</title>
     <link>/posts/about.html</link>
     <guid>/posts/about.html</guid>
     <description><![CDATA[<p>I&#39;m a <em><strong>Software Developer</strong></em> with over a decade experience in mobile and enterprise systems, from early discovery through production. I approach engineering as a <em><strong>craft</strong></em>, valuing human authorship, collaboration and responsible AI-assisted workflows over black-box automation, platform dependency, and proprietary lock-in. <em><strong>Open source</strong></em>, <em><strong>inclusive design</strong></em>, <em><strong>data privacy</strong></em>, <em><strong>digital sovereignty</strong></em>, and <em><strong>sustainable architecture</strong></em> are the principles that guide that practice.</p>
<p>Informed by <em><strong>Critical Theory</strong></em> and <em><strong>Philosophy of Technology</strong></em>, my goal is to build digital experiences and tools grounded in constructive critical thinking. Healthy skepticism, resisting convenience as justification for ethical compromise, and insisting on solutions that respect the diverse communities and ecologies that sustain us.</p>
<p><em><strong>Model collapse</strong></em> is what happens when AI systems train on AI-generated data: outputs converge, variance narrows, and the model consumes its own tail. Whether or not model collapse proves technically inevitable, as a metaphor for the social, algorithmic monocultures follow the same pattern, erasing the particularities, contradictions, and ambiguities that make lived existence meaningful. When systems exclude human authorship, they deny contingency, erase difference, and foreclose creativity — and with them, the possibility of technology that genuinely serves the many, not just the few. Keeping that authorship legible, accountable, and celebrated is not an empty romantic gesture; it is a technical and ethical necessity.</p>
<p>Technology that augments rather than displaces human agency and creativity is worth building.</p>
<p>Get in touch: <a href="mailto:hello&#64;modelcollapse&#46;site"><span>hello&#64;modelcollapse&#46;site</span></a></p>
<p>&nbsp;</p>
<h4 id="some-inspiration">Some Inspiration:</h4>
<ul>
<li><a href="https://criticalengineering.org/" target="_blank" rel="noopener noreferrer">Critical Engineering</a></li>
<li><a href="https://luckysoap.com/statements/handmadeweb.html" target="_blank" rel="noopener noreferrer">A Handmade Web</a></li>
<li><a href="https://motherfuckingwebsite.com/" target="_blank" rel="noopener noreferrer">Motherfucking Website</a></li>
</ul>
<hr>
<blockquote>
<p>&quot;As first principle … the time saved by automatization must be invested in new capacities for dis-automatization, that is, for the production of negentropy … The time liberated by the end of work must be put at the service of an automated culture, but one capable of producing new value and of reinventing work.&quot; — <em><strong>Bernard Stiegler</strong></em>, 2016.</p>
</blockquote>
<hr>]]></description>
</item>

</channel>
</rss>
